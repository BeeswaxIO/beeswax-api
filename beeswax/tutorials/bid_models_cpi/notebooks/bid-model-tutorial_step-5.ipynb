{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a CPI Bid Model (Part 5)\n",
    "We now have our final version of the model, we want to actually turn it into a Beeswax Bid Model.  To do that, we need to take the following steps:\n",
    "* Generate the Prediction Files\n",
    "* Generate the Manifest File\n",
    "* Upload to Beeswax via the Buzz API\n",
    "\n",
    "We'll start with the Prediction Files.\n",
    "\n",
    "### Generate the Prediction Files\n",
    "Bid Models are represented as a set of data files referred to as \"Prediction Files\".  Each file has the following configuration:\n",
    "* pipe-delimited (\"|\") text files\n",
    "* no compression\n",
    "* first row of each file contains headers\n",
    "* at least one \"feature\" field\n",
    "* a required field called \"value\", which represents either the CPM Bid or Bid Multiplier for that row \n",
    "* null values should be left blank\n",
    "* max file size of 100MB (can upload as many files as you like)\n",
    "\n",
    "Our prediction files will look something like this:\n",
    "\n",
    "| app_bundle | display_manager | placement_type   | banner_height | platform_os_version | value          |\n",
    "|------------|-----------------|------------------|---------------|---------------------|----------------|\n",
    "| 1005765746 | Fyber           | BANNER           | 320           | 4.1                 | expected bid |\n",
    "| 1008508212 | SOMA            | BANNER           | 320           | 11.0                | expected bid |\n",
    "| 1016562846 | AerservSDKiOS   | BANNER_AND_VIDEO | null          | 12.0                | expected bid |\n",
    "| ...        | ...             | ...              | ...           | ...                 | ...            |\n",
    "    \n",
    "We want to make sure that we have a prediction for any auction we may want to bid on.  To do that, we are going to grab some auction logs and run them through our SageMaker model endpoint to get the probability of conversion and then multiply by our convesion value to get to our actual bid price.\n",
    "\n",
    "Let's start by loading our auction logs into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import time\n",
    "import json\n",
    "import tarfile\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline\n",
    "from sagemaker.analytics import TrainingJobAnalytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'beeswax-data-us-east-1'\n",
    "AUCTION_LOGS_PATH = 'raw-logs-export/canary/auction/yyyy=2019/MM=03/'\n",
    "NUMFILES = -40000\n",
    "\n",
    "client = boto3.client('s3')\n",
    "resource = boto3.resource('s3')\n",
    "bucket = resource.Bucket(BUCKET)\n",
    "\n",
    "fs = s3fs.S3FileSystem()\n",
    "\n",
    "auction_files = list(bucket.objects.filter(Prefix=AUCTION_LOGS_PATH))\n",
    "auction_frames = []\n",
    "for _file in auction_files[NUMFILES:]:\n",
    "    if not _file.key.endswith('gz'):\n",
    "        continue\n",
    "    with fs.open('s3://{}/{}'.format(BUCKET, _file.key)) as f:\n",
    "        df = pd.read_csv(f, compression='gzip', header=0, sep=',', quotechar='\"')\n",
    "        auction_frames.append(df[['ad_position','app_bundle','app_id','app_name','auction_type',\n",
    "                 'platform_bandwidth', 'banner_height','banner_width','platform_browser',\n",
    "                 'platform_browser_version','platform_carrier','geo_city','content_rating',\n",
    "                 'content_coppa_flag','geo_country','platform_device_make','platform_device_model',\n",
    "                 'platform_device_screen_size','platform_device_type','display_manager',\n",
    "                 'display_manager_ver','domain','environment_type','inventory_interstitial',\n",
    "                 'inventory_source','platform_js','content_language','geo_metro','platform_os',\n",
    "                 'platform_os_version','placement','placement_type','publisher_id','geo_region',\n",
    "                 'site_name','site_id','geo_zip', 'exchange_predicted_view_rate', 'rewarded', \n",
    "                 'video_boxing_allowed', 'video_companion_required','geo_lat', 'geo_long', 'video_playback_method',\n",
    "                 'video_player_size', 'video_start_delay', 'bid_time_epoch_in_usecs']])\n",
    "auction_df = pd.concat(auction_frames, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got some auction logs, so now we need to make the auction logs match the input for our model endpoint.  To do this, we'll take this data through all the transformations we took the original win/conversion files through."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) fill na values with -1 and select unique rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_df = auction_df.fillna(-1).drop_duplicates()\n",
    "auction_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) replace calculated fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_df['hour_of_day_utc'] = pd.to_datetime(auction_df['bid_time_epoch_in_usecs'], unit='us')\n",
    "auction_df['hour_of_day_utc'] = auction_df['hour_of_day_utc'].dt.hour\n",
    "auction_df['lat_long_present'] = pd.notna(auction_df['geo_lat'])\n",
    "auction_df = auction_df.drop(['bid_time_epoch_in_usecs', 'geo_lat', 'geo_long'], axis = 1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) drop unneeded fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/prod_model.json', 'r') as f:\n",
    "    prod_model = json.loads(f.read())\n",
    "    \n",
    "needed_fields = set([col.split('-')[0] for col in prod_model['features']])\n",
    "auction_df = auction_df[list(needed_fields)]\n",
    "auction_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) convert field data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't really have any continuous features, so we'll convert most numeric fields to strings\n",
    "for column in auction_df.select_dtypes(include=['int64','float64', 'bool']).columns:\n",
    "    if column in ['lat_long_present']:\n",
    "        auction_df[column] = auction_df[column].astype('int64')\n",
    "    auction_df[column] = auction_df[column].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5) one-hot encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_df_dummies = pd.get_dummies(auction_df.to_sparse(), sparse=True, prefix_sep='-')\n",
    "auction_df_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6) merge columns\n",
    "Our model expects a specific number of columns in a specific order and this auction data, because of the one-hot encoding contains some separate set of columns.  To make this score-able in our model, we need to make sure the columns match exactly. For each column in the trained model we will:\n",
    "* use the column from our auction data if it exists\n",
    "* if it does not exist, we will create the column and set the values to all 0\n",
    "* drop any additional columns from our auction data (they won't result in any score from our model anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(set(prod_model['features']) & set(auction_df_dummies.columns))\n",
    "auction_df_dummies = auction_df_dummies[cols]\n",
    "auction_df_dummies = auction_df_dummies.to_dense()\n",
    "auction_df_dummies = auction_df_dummies.loc[:,~auction_df_dummies.columns.duplicated()]\n",
    "data_to_score = pd.DataFrame().reindex_like(auction_df)\n",
    "\n",
    "\n",
    "# merge in all the existing columns\n",
    "for feature in prod_model['features']:\n",
    "    try:\n",
    "        data_to_score[feature] = auction_df_dummies[feature]\n",
    "    except KeyError:\n",
    "        data_to_score[feature] = 0\n",
    "    except ValueError:\n",
    "        print('{} is duplicated'.format(feature))\n",
    "\n",
    "# rearrange the columns and drop the unsupported ones\n",
    "data_to_score = data_to_score[prod_model['features']]\n",
    "\n",
    "data_to_score.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is prepared for scoring.  Using our prediction function from previous tutorials, let's go ahead and generate our predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.transformer import Transformer\n",
    "\n",
    "data_to_score.to_csv('data/predictions/input.csv', index=False, header=False)\n",
    "\n",
    "bucket = 'beeswax-tmp-us-east-1'\n",
    "prefix = 'bid-models-test-data/canary/sagemaker'\n",
    "output = 's3://{}/{}/predictions/output'.format(bucket, prefix)\n",
    "input_location = 's3://{}/{}/predictions/input.csv'.format(bucket, prefix)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'predictions/input.csv')).upload_file('data/predictions/input.csv')\n",
    "\n",
    "transformer = Transformer(\n",
    "    base_transform_job_name='Batch-Transform',\n",
    "    model_name='linear-learner-2019-03-23-16-50-13-882',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c5.xlarge',\n",
    "    output_path=output\n",
    ")\n",
    "\n",
    "transformer.transform(input_location, content_type='text/csv', split_type='Line')\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = prefix + '/predictions/output/input.csv.out'\n",
    "boto3.resource('s3').Bucket(bucket).download_file(key, './data/predictions/output.csv')\n",
    "\n",
    "results = []\n",
    "with open('./data/predictions/output.csv', 'r') as f:\n",
    "    output = f.readlines()\n",
    "    for row in output:\n",
    "        results.append(json.loads(row)['score'])\n",
    "\n",
    "auction_df['prediction'] = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have predictions for each of the values in the auction logs we loaded.  Let's see what they look like by ploting them on a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we now have predictions for each row.  Let's take a look at them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(auction_df['prediction'].describe())\n",
    "auction_df['prediction'].hist(bins=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, immediatly, we notice that the predictions are reasonably distributed, which is good, but a significant number of the predictions are below 0.  We obviously can't bid below 0, so let's normalize our predictions by replacing any values below 0 with 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_df['prediction'] = auction_df['prediction'].fillna(0)\n",
    "auction_df.loc[auction_df['prediction'] < 0.0, 'prediction'] = 0\n",
    "print(auction_df.shape)\n",
    "auction_df['prediction'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay that's better.  Now let's calculate our actual CPMs.  Recall that we will calculate our bid as follows:\n",
    "\n",
    ">conversion_value * likelihood_of_conversion = bid_price\n",
    "\n",
    "We also need to express our bid as a cpm, so we will update our formula to the following:\n",
    "\n",
    ">conversion_value * likelihood_of_conversion * 1000 = bid_price\n",
    "\n",
    "And finally, we can substitute in our conversion value:\n",
    "\n",
    ">5 * likelihood_of_conversion * 1000 = bid_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_df['value'] = auction_df['prediction']*5*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_df['value'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we have our prediction data ready, now let's get it ready for upload by:\n",
    "* removing all the \"-1\" values (they can just be empty strings)\n",
    "* dropping the un-needed columns\n",
    "* dropping any data with invalid rows\n",
    "* creating CSV files to upload, and uploading them to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_df = auction_df.drop(['prediction'], axis=1)\n",
    "auction_df = auction_df.replace(to_replace=-1, value='')\n",
    "auction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we don't have any unsupported ENUM values\n",
    "auction_df = auction_df.loc[auction_df['platform_bandwidth'].isin(['CONNECTION_UNKNOWN', 'ETHERNET', 'WIFI', 'CELL_UNKNOWN', 'CELL_2G', 'CELL_3G', 'CELL_4G', ''])]\n",
    "auction_df = auction_df.loc[~auction_df['inventory_source'].isin(['0'])]\n",
    "\n",
    "# make sure metro fields are valid\n",
    "auction_df['geo_metro'] = auction_df['geo_metro'].fillna('0')\n",
    "auction_df['geo_metro'] = auction_df['geo_metro'].replace(to_replace='', value='0')\n",
    "auction_df = auction_df[~auction_df['geo_metro'].apply(lambda x: len(x)>5)]\n",
    "auction_df['geo_metro'] = auction_df['geo_metro'].astype('float')\n",
    "auction_df['geo_metro'] = auction_df['geo_metro'].astype('int')\n",
    "auction_df['geo_metro'] = auction_df['geo_metro'].astype('str')\n",
    "auction_df['geo_metro'] = auction_df['geo_metro'].replace(to_replace='0', value='')\n",
    "auction_df['geo_metro'] = auction_df['geo_metro'].replace(to_replace='1', value='')\n",
    "\n",
    "# make sure all interger fields are integers and not doubles\n",
    "int_fields = ('banner_height', 'banner_width', 'day_of_week_utc', 'hour_of_day_utc',\n",
    "              'rewarded', 'auction_type', 'video_companion_required', 'content_coppa_flag',\n",
    "              'inventory_interstitial', 'platform_js', 'lat_long_present', 'video_start_delay')\n",
    "for col in auction_df:\n",
    "    if col not in int_fields:\n",
    "        continue\n",
    "    auction_df[col] = auction_df[col].replace(to_replace='', value='-100')\n",
    "    auction_df[col] = auction_df[col].astype('int64')\n",
    "    auction_df[col] = auction_df[col].replace(to_replace='-100', value='')\n",
    "\n",
    "# make sure every row has a value\n",
    "auction_df['value'] = auction_df['value'].replace(to_replace='', value='0.0')\n",
    "auction_df['value'] = auction_df['value'].fillna(0.0)\n",
    "auction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_df['platform_device_make'] = auction_df['platform_device_make'].replace(to_replace='-1', value='')\n",
    "auction_df['inventory_interstitial'] = auction_df['inventory_interstitial'].replace(to_replace='-1', value='')\n",
    "auction_df['inventory_interstitial'] = auction_df['inventory_interstitial'].replace(to_replace=-100, value='')\n",
    "auction_df['video_companion_required'] = auction_df['video_companion_required'].replace(to_replace=-100, value='')\n",
    "auction_df['banner_height'] = auction_df['banner_height'].replace(to_replace=-100, value='')\n",
    "auction_df['banner_width'] = auction_df['banner_width'].replace(to_replace=-100, value='')\n",
    "auction_df['rewarded'] = auction_df['rewarded'].replace(to_replace=-100, value='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_df.to_csv('data/predictions/predictions.csv', index=False, header=True, sep='|')\n",
    "\n",
    "timestamp = int(time.time())\n",
    "bucket = 'beeswax-data-us-east-1'\n",
    "prefix = 'bid_models/canary/customer_data_files/sagemaker/'\n",
    "prediction_path = os.path.join(prefix, 'predictions-{}.csv'.format(timestamp))\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(prediction_path).upload_file('data/predictions/predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the Manifest File\n",
    "\n",
    "The manifest file tells Beeswax where to find, and how to interpret your prediction files. This file is a .json file and should have the following format:\n",
    "\n",
    "```{\n",
    "    \"model_predictions\": [\n",
    "        \"<S3 path to prediction file>\",\n",
    "        \"<S3 path to prediction file>\",\n",
    "        ...\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "        \"fields\": [\n",
    "            \"<field name>\",\n",
    "            \"<field name>\",\n",
    "            ...\n",
    "        ]\n",
    "    }\n",
    "}```\n",
    "\n",
    "We can easily generate this from our existing data and upload it to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(auction_df.drop(['value'], axis=1).columns)\n",
    "manifest = {\n",
    "    'model_predictions': [\n",
    "        's3://{}/{}'.format(bucket, prediction_path)\n",
    "    ],\n",
    "    'metadata': {\n",
    "        'fields': features\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('data/predictions/manifest.json', 'w') as f:\n",
    "    f.write(json.dumps(manifest))\n",
    "\n",
    "prefix = 'bid_models/canary/customer_manifests/sagemaker/'\n",
    "manifest_path = os.path.join(prefix, 'manifest-{}.csv'.format(timestamp))\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(manifest_path).upload_file('data/predictions/manifest.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload to Buzz\n",
    "\n",
    "We've reached the final step and its time to actually upload our model to Beeswax via the Buzz API.  To do this, we will first create a `bid_model` object and attach a `bid_model_version`, then we will create a `campaign` and attach the `bid_model`.\n",
    "\n",
    "These steps can all be done via the UI as well, but since we've written everything else in Python we might as well do our upload that way as well.\n",
    "\n",
    "##### 1) Create a Bid Model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buzz_username = ''  # enter username\n",
    "buzz_password = ''  # enter password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, authenticate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = requests.Session()\n",
    "payload = {\n",
    "    'email': buzz_username,\n",
    "    'password': buzz_password,\n",
    "    'keep_logged_in': True\n",
    "}\n",
    "s.post('https://canary.api.beeswax.com/rest/authenticate', json=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create the `bid_model` object.  We will use the `value_type` \"BID\", but could also specify \"Multiplier\" if we wanted the value to be multiplied into the base bid for the bidding strategy we will select later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    'active': True,\n",
    "    'bid_model_name': 'cpi_tutorial-{}'.format(timestamp),\n",
    "    'value_type': 'BID'\n",
    "}\n",
    "response = s.post('https://canary.api.beeswax.com/rest/bid_model', json=payload)\n",
    "bid_model_id = response.json()['payload']['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to attach a `bid_model_version` to our `bid_model`.  This is where we will actually tell Beeswax about our manifest file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    'active': True,\n",
    "    'bid_model_id': response.json()['payload']['id'],\n",
    "    'bid_model_version_name': 'cpi_tutorial-v_{}'.format(timestamp),\n",
    "    'manifest_s3_path': 's3://{}/{}'.format(bucket, manifest_path)\n",
    "}\n",
    "response = s.post('https://canary.api.beeswax.com/rest/bid_model_version', json=payload)\n",
    "version_id = response.json()['payload']['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, update the `bid_model` to tell it which version to use (the one we just created):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    'bid_model_id': bid_model_id,\n",
    "    'current_version': version_id\n",
    "}\n",
    "response = s.put('https://canary.api.beeswax.com/rest/bid_model', json=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Traffic a Campaign\n",
    "\n",
    "First, create the `campaign` itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    'active': True,\n",
    "    'advertiser_id': 76,\n",
    "    'campaign_name': 'cpi_tutorial-{}'.format(timestamp),\n",
    "    'budget_type': 1,\n",
    "    'campaign_budget': 10000,\n",
    "    'start_date': '01/01/2019'\n",
    "}\n",
    "response = s.post('https://canary.api.beeswax.com/rest/campaign', json=payload)\n",
    "campaign_id = response.json()['payload']['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a `bid_modifier` and attach the `bid_model` to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    'active': True,\n",
    "    'bid_model_id': bid_model_id,\n",
    "    'bid_modifier_name': 'cpi_tutorial-{}'.format(timestamp)\n",
    "}\n",
    "response = s.post('https://canary.api.beeswax.com/rest/bid_modifier', json=payload)\n",
    "bid_modifier_id = response.json()['payload']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    'bid_modifier_id': bid_modifier_id,\n",
    "    'campaign_id': campaign_id,\n",
    "    'max_bid': 20.0\n",
    "}\n",
    "response = s.put('https://canary.api.beeswax.com/rest/campaign', json=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a `line_item` for our `campaign`.  This is where we will specify our default bidding strategy, add targeting and associate creatives.  For our test, we will use a flat cpm bidding strategy with a `cpm_bid` of $0.01.  In practice, this means we will only win when we have a hit on our Bid Model since we will otherwise be below the bid floor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    'campaign_id': campaign_id,\n",
    "    'advertiser_id': 76,\n",
    "    'line_item_type_id': 0,  # banner\n",
    "    'line_item_name': 'cpi_tutorial-{}'.format(timestamp),\n",
    "    'line_item_budget': 1000,\n",
    "    'budget_type': 1,  # impression\n",
    "    'bidding': {\n",
    "        'bidding_strategy': 'cpm',\n",
    "        'values': {\n",
    "            'cpm_bid': 0.01 \n",
    "        }\n",
    "    },\n",
    "    'start_date': '01/01/2019'\n",
    "}\n",
    "response = s.post('https://canary.api.beeswax.com/rest/line_item', json=payload)\n",
    "line_item_id = response.json()['payload']['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `line_item` also needs a `targeting_template`.  We could get fancy and only target keys that are present in our `bid_model` but for the sake of simplicity, let's just target all mobile traffic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    'strategy_id': 1,\n",
    "    'targeting': {\n",
    "        'inventory': [\n",
    "            {\n",
    "                'include': {\n",
    "                    'environment_type': [1]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "response = s.post('https://canary.api.beeswax.com/rest/targeting_template', json=payload)\n",
    "targeting_template_id = response.json()['payload']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    'line_item_id': line_item_id,\n",
    "    'targeting_template_id': targeting_template_id\n",
    "}\n",
    "response = s.put('https://canary.api.beeswax.com/rest/line_item', json=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to add `creative_line_item` associations and then we can set everything live:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for creative_id in [2218, 2219, 2220]:\n",
    "    payload = {\n",
    "        'line_item_id': line_item_id,\n",
    "        'creative_id': creative_id,\n",
    "        'active': True\n",
    "    }\n",
    "    response = s.post('https://canary.api.beeswax.com/rest/creative_line_item', json=payload)\n",
    "\n",
    "payload = {\n",
    "    'line_item_id': line_item_id,\n",
    "    'active': True\n",
    "}\n",
    "response = s.put('https://canary.api.beeswax.com/rest/line_item', json=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! We've trained, tuned and deployed a live Bid Model to the Beeswax platform.  At this point we can head over to the Beeswax UI and monitor our line item to see how it's performing!\n",
    "\n",
    "Hopefully this tutorial has given you the basics required to get started.  There are a few topics that we've left out, but plan to cover in the future:\n",
    "* Monitoring a live model and making updates to improve performance\n",
    "* Factoring in auction dynamics such as auction type (1st vs 2nd), market price estimation, etc\n",
    "* Using a Bid Model in conjunction with device level scores.\n",
    "\n",
    "Stay tuned!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python2",
   "language": "python",
   "name": "conda_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
